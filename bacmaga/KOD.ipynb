{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7bCILWQ7nxR"
   },
   "source": [
    "# Model predykcji wysokiego stresu (HIGH)\n",
    "\n",
    "Notebook uporządkowany: wczytanie danych → preprocessing → modele → walidacja CV → tuning ETC → interpretacja cech → zapis artefaktów.\n"
   ],
   "id": "W7bCILWQ7nxR"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FZM47fRR7nxW",
    "ExecuteTime": {
     "end_time": "2026-01-19T19:52:04.177754300Z",
     "start_time": "2026-01-19T19:52:03.947623300Z"
    }
   },
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, make_scorer\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import joblib\n"
   ],
   "id": "FZM47fRR7nxW",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4YjfeNz7nxa"
   },
   "source": [
    "## 1) Konfiguracja"
   ],
   "id": "y4YjfeNz7nxa"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0Miy_0vt7nxc",
    "ExecuteTime": {
     "end_time": "2026-01-19T19:52:06.459981400Z",
     "start_time": "2026-01-19T19:52:06.428537800Z"
    }
   },
   "source": [
    "class Config:\n",
    "    excel_path: str = \"prawidlowy_excel.xlsx\"\n",
    "    sheet_name: str | None = None\n",
    "\n",
    "    stress_high_threshold: float = 8.0\n",
    "    test_size: float = 0.35\n",
    "    random_state: int = 42\n",
    "\n",
    "cfg = Config()\n"
   ],
   "id": "0Miy_0vt7nxc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29j8nYEJ7nxd"
   },
   "source": [
    "## 2) Funkcje pomocnicze + testy jednostkowe (czytelne, z liczbami)"
   ],
   "id": "29j8nYEJ7nxd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1eUtzrd7nxd",
    "outputId": "7649152b-bb74-4903-8583-e6906b17c681",
    "ExecuteTime": {
     "end_time": "2026-01-19T19:52:08.636962200Z",
     "start_time": "2026-01-19T19:52:08.331658900Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "def find_stress_column(df: pd.DataFrame) -> str:\n",
    "    cols_lower = {c: str(c).lower() for c in df.columns}\n",
    "    stress_candidates = [c for c in df.columns if \"stres\" in cols_lower[c]]\n",
    "    if not stress_candidates:\n",
    "        raise ValueError(\"Nie znalazłem kolumny stresu (musi zawierać 'stres').\")\n",
    "\n",
    "    for c in stress_candidates:\n",
    "        cl = cols_lower[c]\n",
    "        if \"poziom\" in cl or \"skali\" in cl or \"skala\" in cl:\n",
    "            return c\n",
    "    return stress_candidates[0]\n",
    "\n",
    "def coerce_numeric_commas(series: pd.Series) -> pd.Series:\n",
    "    s = series.astype(str).str.replace(\",\", \".\", regex=False).str.strip()\n",
    "    s = s.replace({\"nan\": np.nan, \"None\": np.nan, \"none\": np.nan, \"\": np.nan})\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def make_target_from_stress(stress_num: pd.Series, thr: float) -> pd.Series:\n",
    "    return pd.Series(np.where(stress_num >= thr, \"HIGH\", \"NOT_HIGH\"), index=stress_num.index)\n",
    "\n",
    "def make_preprocess():\n",
    "    num_sel = make_column_selector(dtype_include=np.number)\n",
    "    cat_sel = make_column_selector(dtype_exclude=np.number)\n",
    "\n",
    "    num_pipe = Pipeline(steps=[\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline(steps=[\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[(\"num\", num_pipe, num_sel), (\"cat\", cat_pipe, cat_sel)],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "# ===== TESTY (verbose, z obliczeniami) =====\n",
    "def _test_find_stress_column_verbose():\n",
    "    print(\"TEST: find_stress_column\\n\" + \"-\"*35)\n",
    "    df0 = pd.DataFrame({\"Poziom stresu (skala 1-10)\": [1, 2], \"wiek\": [20, 21]})\n",
    "    res0 = find_stress_column(df0)\n",
    "    print(\"Kolumny:\", list(df0.columns))\n",
    "    print(\"Wybrana:\", res0)\n",
    "    assert res0 == \"Poziom stresu (skala 1-10)\"\n",
    "    print(\"OK\\n\")\n",
    "\n",
    "    df1 = pd.DataFrame({\"stres\": [1, 2], \"x\": [0, 1]})\n",
    "    res1 = find_stress_column(df1)\n",
    "    print(\"Kolumny:\", list(df1.columns))\n",
    "    print(\"Wybrana:\", res1)\n",
    "    assert res1 == \"stres\"\n",
    "    print(\"OK\\n\")\n",
    "\n",
    "    try:\n",
    "        find_stress_column(pd.DataFrame({\"abc\": [1]}))\n",
    "        raise AssertionError(\"Powinien być wyjątek, a nie był.\")\n",
    "    except ValueError as e:\n",
    "        print(\"Oczekiwany wyjątek:\", repr(e))\n",
    "        print(\"OK\\n\")\n",
    "\n",
    "def _test_coerce_numeric_commas_verbose():\n",
    "    print(\"TEST: coerce_numeric_commas\\n\" + \"-\"*35)\n",
    "    s = pd.Series([\"1,5\", \"2\", \"abc\", None, \"\"])\n",
    "    out = coerce_numeric_commas(s)\n",
    "    df_show = pd.DataFrame({\"in\": s, \"out\": out})\n",
    "    print(df_show)\n",
    "    assert np.isclose(out.iloc[0], 1.5)\n",
    "    assert np.isclose(out.iloc[1], 2.0)\n",
    "    assert np.isnan(out.iloc[2])\n",
    "    assert np.isnan(out.iloc[3])\n",
    "    assert np.isnan(out.iloc[4])\n",
    "    print(\"OK\\n\")\n",
    "\n",
    "def _test_make_target_from_stress_verbose():\n",
    "    print(\"TEST: make_target_from_stress\\n\" + \"-\"*35)\n",
    "    s = pd.Series([7.9, 8.0, 10.0])\n",
    "    y = make_target_from_stress(s, 8.0)\n",
    "    df_show = pd.DataFrame({\"stress\": s, \"thr\": 8.0, \"class\": y})\n",
    "    print(df_show)\n",
    "    assert list(y) == [\"NOT_HIGH\", \"HIGH\", \"HIGH\"]\n",
    "    print(\"OK\\n\")\n",
    "\n",
    "_test_find_stress_column_verbose()\n",
    "_test_coerce_numeric_commas_verbose()\n",
    "_test_make_target_from_stress_verbose()\n",
    "\n",
    "print(\"OK — testy funkcji pomocniczych przeszły.\")\n"
   ],
   "id": "z1eUtzrd7nxd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: find_stress_column\n",
      "-----------------------------------\n",
      "Kolumny: ['Poziom stresu (skala 1-10)', 'wiek']\n",
      "Wybrana: Poziom stresu (skala 1-10)\n",
      "OK\n",
      "\n",
      "Kolumny: ['stres', 'x']\n",
      "Wybrana: stres\n",
      "OK\n",
      "\n",
      "Oczekiwany wyjątek: ValueError(\"Nie znalazłem kolumny stresu (musi zawierać 'stres').\")\n",
      "OK\n",
      "\n",
      "TEST: coerce_numeric_commas\n",
      "-----------------------------------\n",
      "     in  out\n",
      "0   1,5  1.5\n",
      "1     2  2.0\n",
      "2   abc  NaN\n",
      "3  None  NaN\n",
      "4        NaN\n",
      "OK\n",
      "\n",
      "TEST: make_target_from_stress\n",
      "-----------------------------------\n",
      "   stress  thr     class\n",
      "0     7.9  8.0  NOT_HIGH\n",
      "1     8.0  8.0      HIGH\n",
      "2    10.0  8.0      HIGH\n",
      "OK\n",
      "\n",
      "OK — testy funkcji pomocniczych przeszły.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zJ1UoQ67nxe"
   },
   "source": [
    "## 3) Wczytanie i przygotowanie danych (X, y)"
   ],
   "id": "2zJ1UoQ67nxe"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVIly98Y7nxe",
    "outputId": "153082b4-a4d7-4594-f23b-1c9789bd2308",
    "ExecuteTime": {
     "end_time": "2026-01-19T19:52:20.869900600Z",
     "start_time": "2026-01-19T19:52:20.778305500Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(cfg.excel_path):\n",
    "    raise FileNotFoundError(f\"Nie widzę pliku: {cfg.excel_path}. Ustaw cfg.excel_path poprawnie.\")\n",
    "\n",
    "raw = pd.read_excel(cfg.excel_path, sheet_name=cfg.sheet_name, engine=\"openpyxl\")\n",
    "df = raw[list(raw.keys())[0]].copy() if isinstance(raw, dict) else raw.copy()\n",
    "df = df.dropna(how=\"all\")\n",
    "\n",
    "stress_col = find_stress_column(df)\n",
    "stress_num = coerce_numeric_commas(df[stress_col])\n",
    "mask = stress_num.notna()\n",
    "\n",
    "df = df.loc[mask].copy()\n",
    "stress_num = stress_num.loc[mask].copy()\n",
    "\n",
    "y = make_target_from_stress(stress_num, cfg.stress_high_threshold)\n",
    "y.name = \"stress_class\"\n",
    "\n",
    "X = df.drop(columns=[stress_col], errors=\"ignore\").copy()\n",
    "\n",
    "# Konwersja \"liczb z przecinkami\" w kolumnach tekstowych, jeśli >=70% to liczby\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        maybe = coerce_numeric_commas(X[c])\n",
    "        if maybe.notna().mean() >= 0.70:\n",
    "            X[c] = maybe\n",
    "\n",
    "print(\"Dane X:\", X.shape, \" | y:\", y.shape)\n",
    "print(\"Rozkład klas:\\n\", y.value_counts())\n",
    "print(\"Kolumna stresu:\", stress_col)\n"
   ],
   "id": "aVIly98Y7nxe",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Nie widzę pliku: prawidlowy_excel.xlsx. Ustaw cfg.excel_path poprawnie.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(cfg.excel_path):\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNie widzę pliku: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcfg.excel_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Ustaw cfg.excel_path poprawnie.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      6\u001B[39m raw = pd.read_excel(cfg.excel_path, sheet_name=cfg.sheet_name, engine=\u001B[33m\"\u001B[39m\u001B[33mopenpyxl\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      7\u001B[39m df = raw[\u001B[38;5;28mlist\u001B[39m(raw.keys())[\u001B[32m0\u001B[39m]].copy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(raw, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m raw.copy()\n",
      "\u001B[31mFileNotFoundError\u001B[39m: Nie widzę pliku: prawidlowy_excel.xlsx. Ustaw cfg.excel_path poprawnie."
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx-6UOJj7nxf"
   },
   "source": [
    "## 4) Podział train/test (holdout)"
   ],
   "id": "vx-6UOJj7nxf"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFaXspFG7nxf",
    "outputId": "0b4ce9c1-5965-4a9b-ccc9-837a6f1e5a3d"
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=cfg.test_size,\n",
    "    random_state=cfg.random_state,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"Train klasy:\\n\", y_train.value_counts())\n",
    "print(\"Test  klasy:\\n\", y_test.value_counts())\n"
   ],
   "id": "dFaXspFG7nxf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idW3loXX7nxg"
   },
   "source": [
    "## 5) Modele bazowe: Logistic Regression vs ExtraTrees (holdout)"
   ],
   "id": "idW3loXX7nxg"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YPIYY9-o7nxg",
    "outputId": "01fb55ef-f6e0-4f10-f664-6255c9ed5965"
   },
   "source": [
    "f1_high_scorer = make_scorer(f1_score, pos_label=\"HIGH\")\n",
    "\n",
    "pipe_lr = Pipeline(steps=[\n",
    "    (\"preprocess\", make_preprocess()),\n",
    "    (\"model\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", random_state=cfg.random_state))\n",
    "])\n",
    "\n",
    "pipe_etc = Pipeline(steps=[\n",
    "    (\"preprocess\", make_preprocess()),\n",
    "    (\"model\", ExtraTreesClassifier(\n",
    "        n_estimators=600,\n",
    "        random_state=cfg.random_state,\n",
    "        n_jobs=1,\n",
    "        class_weight=\"balanced\",\n",
    "        min_samples_leaf=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "def eval_holdout(pipe, name):\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "\n",
    "    ba = balanced_accuracy_score(y_test, pred)\n",
    "    f1h = f1_score(y_test, pred, pos_label=\"HIGH\")\n",
    "    cm = confusion_matrix(y_test, pred, labels=[\"HIGH\",\"NOT_HIGH\"])\n",
    "\n",
    "    print(f\"\\n{name} — HOLDOUT\")\n",
    "    print(\"BA:\", round(float(ba), 4), \" | F1(HIGH):\", round(float(f1h), 4))\n",
    "    print(\"CM (rows=true [HIGH, NOT_HIGH], cols=pred [HIGH, NOT_HIGH]):\\n\", cm)\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "eval_holdout(pipe_lr, \"LogisticRegression\")\n",
    "eval_holdout(pipe_etc, \"ExtraTreesClassifier\")\n"
   ],
   "id": "YPIYY9-o7nxg",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muZTG40g7nxh"
   },
   "source": [
    "## 6) Stabilna ocena: RepeatedStratifiedKFold 5×5 (CV)"
   ],
   "id": "muZTG40g7nxh"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n1Urcnea7nxh",
    "outputId": "31e32526-0920-4040-a62b-424ed3476aa7"
   },
   "source": [
    "cv_rep = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=cfg.random_state)\n",
    "\n",
    "scoring = {\n",
    "    \"bal_acc\": \"balanced_accuracy\",\n",
    "    \"f1_high\": f1_high_scorer,\n",
    "    \"roc_auc\": \"roc_auc\"\n",
    "}\n",
    "\n",
    "def cv_report(pipe, name):\n",
    "    out = cross_validate(pipe, X, y, cv=cv_rep, scoring=scoring, n_jobs=1, return_train_score=False)\n",
    "    ba = out[\"test_bal_acc\"]; f1h = out[\"test_f1_high\"]; roc = out[\"test_roc_auc\"]\n",
    "    print(f\"\\n{name} (Repeated 5×5 CV)\")\n",
    "    print(f\"BA      : {ba.mean():.4f} ± {ba.std(ddof=1):.4f}\")\n",
    "    print(f\"F1(HIGH): {f1h.mean():.4f} ± {f1h.std(ddof=1):.4f}\")\n",
    "    print(f\"ROC-AUC : {roc.mean():.4f} ± {roc.std(ddof=1):.4f}\")\n",
    "    return out\n",
    "\n",
    "out_lr = cv_report(pipe_lr, \"LOGISTIC REGRESSION\")\n",
    "out_etc = cv_report(pipe_etc, \"ETC (wstępne parametry)\")\n"
   ],
   "id": "n1Urcnea7nxh",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1S9x6b2C7nxi"
   },
   "source": [
    "## 7) Strojenie hiperparametrów ETC (RandomizedSearchCV na Repeated CV)"
   ],
   "id": "1S9x6b2C7nxi"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNt66Fe07nxi",
    "outputId": "6935a0bf-6f8e-4f80-9d79-75426a390398"
   },
   "source": [
    "param_dist = {\n",
    "    \"model__n_estimators\": [400, 800, 1200],\n",
    "    \"model__max_depth\": [None, 5, 8, 12, 16, 20],\n",
    "    \"model__min_samples_split\": [2, 5, 10, 20, 40],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4, 8, 12, 20],\n",
    "    \"model__max_features\": [\"sqrt\", \"log2\", 0.3, 0.5, 0.8, None],\n",
    "    \"model__bootstrap\": [False, True],\n",
    "    \"model__class_weight\": [None, \"balanced\"],\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe_etc,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,\n",
    "    scoring=scoring,\n",
    "    refit=\"f1_high\",\n",
    "    cv=cv_rep,\n",
    "    n_jobs=1,\n",
    "    random_state=cfg.random_state,\n",
    "    verbose=1,\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "\n",
    "best_pipe = search.best_estimator_\n",
    "\n",
    "print(\"\\nNajlepszy wynik (CV) F1(HIGH):\", round(float(search.best_score_), 4))\n",
    "print(\"Najlepsze parametry:\")\n",
    "for k, v in search.best_params_.items():\n",
    "    print(\" -\", k, \"=\", v)\n",
    "\n",
    "# raport stabilności dla best_pipe\n",
    "out_best = cv_report(best_pipe, \"BEST ETC\")\n"
   ],
   "id": "uNt66Fe07nxi",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqniTNov7nxi"
   },
   "source": [
    "## 8) Wpływ zmiennych: permutation importance (na holdout)"
   ],
   "id": "bqniTNov7nxi"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "id": "7ynBp-AT7nxj",
    "outputId": "4c950aed-a5dd-475f-e1e9-aea0da15b1a7"
   },
   "source": [
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "perm = permutation_importance(\n",
    "    best_pipe,\n",
    "    X_test, y_test,\n",
    "    scoring=f1_high_scorer,\n",
    "    n_repeats=30,\n",
    "    random_state=cfg.random_state,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "feat_names = best_pipe.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "imp_perm = pd.DataFrame({\n",
    "    \"feature\": feat_names,\n",
    "    \"importance_mean\": perm.importances_mean,\n",
    "    \"importance_std\": perm.importances_std\n",
    "}).sort_values(\"importance_mean\", ascending=False)\n",
    "\n",
    "display(imp_perm.head(20))\n"
   ],
   "id": "7ynBp-AT7nxj",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "joblib.dump(best_pipe, \"best_model.joblib\")\n"
   ],
   "id": "890131b69a93411b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "def holdout_report(pipe, X_test, y_test, name=\"MODEL\"):\n",
    "    pred = pipe.predict(X_test)\n",
    "    ba = balanced_accuracy_score(y_test, pred)\n",
    "    f1h = f1_score(y_test, pred, pos_label=\"HIGH\")\n",
    "    cm = confusion_matrix(y_test, pred, labels=[\"HIGH\",\"NOT_HIGH\"])\n",
    "    rep = classification_report(y_test, pred)\n",
    "\n",
    "    txt = (\n",
    "        f\"{name} — HOLDOUT\\n\"\n",
    "        f\"Balanced accuracy: {ba:.4f}\\n\"\n",
    "        f\"F1(HIGH): {f1h:.4f}\\n\\n\"\n",
    "        f\"Confusion matrix (rows=true [HIGH, NOT_HIGH], cols=pred [HIGH, NOT_HIGH]):\\n{cm}\\n\\n\"\n",
    "        f\"Classification report:\\n{rep}\\n\"\n",
    "    )\n",
    "    metrics = {\"balanced_accuracy\": float(ba), \"f1_high\": float(f1h)}\n",
    "    return txt, metrics\n",
    "\n",
    "# folder na wyniki\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "# raport i metryki dla najlepszego modelu\n",
    "report_text, metrics = holdout_report(best_pipe, X_test, y_test, name=\"BEST ETC\")\n",
    "\n",
    "(Path(\"results\") / \"metrics_report.txt\").write_text(report_text, encoding=\"utf-8\")\n",
    "pd.DataFrame([metrics]).to_csv(\"results/metrics_holdout.csv\", index=False)\n",
    "\n",
    "# zapis najlepszych parametrów z RandomizedSearchCV\n",
    "(Path(\"results\") / \"best_params.json\").write_text(\n",
    "    json.dumps(search.best_params_, ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# zapis importance (to jest Twoje imp_perm z notebooka)\n",
    "imp_perm.head(20).to_csv(\"results/feature_importance_top20.csv\", index=False)\n",
    "imp_perm.to_csv(\"results/feature_importance_all.csv\", index=False)\n",
    "\n",
    "# zapis modelu\n",
    "joblib.dump(best_pipe, \"results/best_model.joblib\")\n",
    "\n"
   ],
   "id": "28e8ab40c1775f2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "64a21175e1cbdfb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ce435f0435a5623",
   "outputs": [],
   "execution_count": null
  }
 ]
}
